from typing import List, Dict, Any, TypedDict, Literal, Union
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph
from pydantic import BaseModel, Field
import base64
from pathlib import Path
from openai import OpenAI
import os
from medical_agent.utils import call_qwen_vl_api, safe_json_load, end_timer_and_print
from medical_agent.utils import *
from medical_agent.table_format import create_formatted_df, ROW_INDEX
from typing import TypedDict, get_type_hints, Any
from medical_agent.prompts import FILL_IN_FORM_PROMPT, FILLIN_PROMPT_2, FILLIN_PROMPT_3, FILLIN_PROMPT_4, FILLIN_PROMPT_5, REPORT_CLASSIFIER_PROMPT, ULTRASOUND_EXTRACT_PROMPT
import json
import pandas as pd
from medical_agent.gui import show_popup_with_df
from medical_agent.utils import ROOT_DIR

# Define message types
class Message(TypedDict):
    role: Literal["user", "assistant", "system"]
    content: Union[str, Dict[str, Any]]
    content_type: Literal["text", "image"] = "text"


# Define the system prompt
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—åŠ©æ‰‹ï¼Œä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯å¸®åŠ©åŒ»ç”Ÿæ•´ç†ç—…ä¾‹ï¼Œè¯Šæ–­æŠ¥å‘Šç­‰æ–‡ä»¶æˆ–å›¾ç‰‡ï¼Œå¹¶å°†å…¶æ•´ç†æˆç»“æ„åŒ–æ•°æ®å­˜å‚¨èµ·æ¥ã€‚å¿…è¦æ—¶ï¼Œä½ ä¹Ÿå¯ä»¥å›ç­”ç”¨æˆ·çš„åŒ»ç–—é—®é¢˜ã€‚å¦‚æœå¯èƒ½ï¼Œåœ¨å›ç­”åŒ»ç–—é—®é¢˜æ—¶è¯·å°½é‡æä¾›æ¥æºã€‚"""

def process_ultrasound_location(location, ocr, qwen, row_index, system_prompt):
    """å¤„ç†å•ä¸ªè¶…å£°æµ‹é‡é¡¹ç›®çš„å‡½æ•°ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œ"""
    if location not in row_index:
        return None, None, None
        
    ridx = row_index[location]
    
    # åŠ¨æ€ç”Ÿæˆåˆ«åæ˜ å°„è§„åˆ™
    try:
        from config_loader import generate_alias_prompt_section
        dynamic_alias_rules = generate_alias_prompt_section()
    except (ImportError, Exception):
        # ä¸ä½¿ç”¨ä»»ä½•åˆ«åè§„åˆ™ï¼Œè®©AIè¿›è¡Œç²¾ç¡®åŒ¹é…
        dynamic_alias_rules = ""
    
    input_prompt = ULTRASOUND_EXTRACT_PROMPT.format(
        ocr_text=ocr, 
        location=location,
        dynamic_alias_rules=dynamic_alias_rules
    )
    
    # å®ç°é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    max_retries = 3
    attempt = 0
    
    while attempt < max_retries:
        try:
            completion = qwen.chat.completions.create(
                model="qwen-max-0125",
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': input_prompt}
                ]
            )
            text = completion.choices[0].message.content
            tmp = safe_json_load(text)
            return location, ridx, tmp
        except Exception as e:
            attempt += 1
            if attempt < max_retries:
                # æŒ‡æ•°é€€é¿ï¼šç­‰å¾…æ—¶é—´ä¸º 2^attempt ç§’ï¼Œæœ€å¤§ç­‰å¾…32ç§’
                wait_time = min(2 ** attempt, 32)
                import time
                time.sleep(wait_time)
            else:
                print(f"âŒ {location} å¤„ç†å¤±è´¥: {e}")
                return location, ridx, None
    
    return location, ridx, None

def calculate_ea_ratios(formatted_table):
    """
    è‡ªåŠ¨è®¡ç®—äºŒå°–ç“£/ä¸‰å°–ç“£çš„E/Aæ¯”å€¼
    
    Args:
        formatted_table (pd.DataFrame): æ ¼å¼åŒ–çš„è¡¨æ ¼
        
    Returns:
        pd.DataFrame: æ·»åŠ äº†E/Aæ¯”å€¼è®¡ç®—çš„è¡¨æ ¼
    """
    # å®šä¹‰Eå³°å’ŒAå³°çš„æœç´¢æ¨¡å¼
    valve_patterns = {
        "äºŒå°–ç“£": {
            "e_patterns": ["äºŒå°–ç“£E", "MV E", "Mitral E", "äºŒå°–ç“£Eå³°", "MV Eå³°"],
            "a_patterns": ["äºŒå°–ç“£A", "MV A", "Mitral A", "äºŒå°–ç“£Aå³°", "MV Aå³°"],
            "ratio_name": "äºŒå°–ç“£E/Aæ¯”å€¼",
            "ratio_english": "MV E/A ratio",
            "ratio_abbr": "MV E/A"
        },
        "ä¸‰å°–ç“£": {
            "e_patterns": ["ä¸‰å°–ç“£E", "TV E", "Tricuspid E", "ä¸‰å°–ç“£Eå³°", "TV Eå³°"],
            "a_patterns": ["ä¸‰å°–ç“£A", "TV A", "Tricuspid A", "ä¸‰å°–ç“£Aå³°", "TV Aå³°"],
            "ratio_name": "ä¸‰å°–ç“£E/Aæ¯”å€¼",
            "ratio_english": "TV E/A ratio", 
            "ratio_abbr": "TV E/A"
        }
    }
    
    ea_ratios_added = []
    
    for valve_name, patterns in valve_patterns.items():
        # æŸ¥æ‰¾Eå³°å’ŒAå³°çš„æ•°å€¼
        e_value = None
        a_value = None
        e_row_idx = None
        a_row_idx = None
        
        # æœç´¢Eå³°
        for idx, row in formatted_table.iterrows():
            name = str(row['åç§°']).strip()
            value = str(row['æ•°å€¼']).strip()
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…Eå³°æ¨¡å¼ä¸”æœ‰æ•°å€¼
            for pattern in patterns["e_patterns"]:
                if pattern in name and value and value != "" and value != "-" and value != "NO":
                    try:
                        e_value = float(value)
                        e_row_idx = idx
                        break
                    except ValueError:
                        continue
            if e_value is not None:
                break
        
        # æœç´¢Aå³°  
        for idx, row in formatted_table.iterrows():
            name = str(row['åç§°']).strip()
            value = str(row['æ•°å€¼']).strip()
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…Aå³°æ¨¡å¼ä¸”æœ‰æ•°å€¼
            for pattern in patterns["a_patterns"]:
                if pattern in name and value and value != "" and value != "-" and value != "NO":
                    try:
                        a_value = float(value)
                        a_row_idx = idx
                        break
                    except ValueError:
                        continue
            if a_value is not None:
                break
        
        # å¦‚æœæ‰¾åˆ°äº†å®Œæ•´çš„Eå³°å’ŒAå³°æ•°å€¼ï¼Œè®¡ç®—E/Aæ¯”å€¼
        if e_value is not None and a_value is not None and a_value != 0:
            ea_ratio = round(e_value / a_value, 2)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å¯¹åº”çš„E/Aæ¯”å€¼è¡Œ
            ratio_exists = False
            for idx, row in formatted_table.iterrows():
                name = str(row['åç§°']).strip()
                if patterns["ratio_name"] in name or patterns["ratio_abbr"] in name:
                    # æ›´æ–°ç°æœ‰çš„æ¯”å€¼
                    formatted_table.at[idx, 'æ•°å€¼'] = str(ea_ratio)
                    ratio_exists = True
                    break
            
            # å¦‚æœä¸å­˜åœ¨ï¼Œæ·»åŠ æ–°è¡Œ
            if not ratio_exists:
                new_row = {
                    "åç§°": f"{patterns['ratio_name']}({patterns['ratio_abbr']})",
                    "è‹±æ–‡": patterns["ratio_english"],
                    "æ–‘å—ç§ç±»": "",
                    "ç±»å‹": "",
                    "ç—‡çŠ¶": "",
                    "æ•°å€¼": str(ea_ratio),
                    "å•ä½": "",  # E/Aæ¯”å€¼æ— å•ä½
                    "ç‹­çª„ç¨‹åº¦": "",
                    "é—­å¡": "å¦"
                }
                
                # ä½¿ç”¨pd.concatæ·»åŠ æ–°è¡Œåˆ°è¡¨æ ¼å¼€å¤´
                new_row_df = pd.DataFrame([new_row])
                formatted_table = pd.concat([new_row_df, formatted_table], ignore_index=True)
                
                ea_ratios_added.append(f"{patterns['ratio_name']}: {ea_ratio}")
    
    return formatted_table

def separate_value_and_unit(value_str):
    """
    å°†å¸¦å•ä½çš„æ•°å€¼å­—ç¬¦ä¸²åˆ†ç¦»æˆçº¯æ•°å€¼å’Œå•ä½
    
    Args:
        value_str (str): å¸¦å•ä½çš„æ•°å€¼å­—ç¬¦ä¸²ï¼Œå¦‚ "700m/s", "500x300cm", "18mmHg"
    
    Returns:
        tuple: (çº¯æ•°å€¼, å•ä½)
        
    Examples:
        "700m/s" -> ("700", "m/s")
        "500x300cm" -> ("500x300", "cm") 
        "18mmHg" -> ("18", "mmHg")
        "59%" -> ("59", "%")
        "18" -> ("18", "")
    """
    import re
    
    if not value_str or value_str == "-" or value_str == "NO":
        return value_str, ""
    
    value_str = str(value_str).strip()
    
    # å®šä¹‰å¸¸è§çš„åŒ»å­¦å•ä½ï¼ˆæŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œä¼˜å…ˆåŒ¹é…è¾ƒé•¿çš„å•ä½ï¼‰
    common_units = [
        'mmHg', 'ml/mÂ²', 'cm/s', 'mm/s', 'm/s', 'mmHg/s', 'msec', 
        'cmÂ²', 'mmÂ²', 'mÂ²', 'bpm', 'cm', 'mm', 'm', 'ml', 'kPa', 
        'Hz', 'sec', 'min', '%', 'g', 'kg', 'l'
    ]
    
    # å…ˆå°è¯•æ‰¾åˆ°æœ€é•¿åŒ¹é…çš„å•ä½åç¼€
    matched_unit = ""
    numeric_part = value_str
    
    for unit in common_units:
        # æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä»¥è¿™ä¸ªå•ä½ç»“å°¾
        if value_str.lower().endswith(unit.lower()):
            # æå–æ•°å€¼éƒ¨åˆ†ï¼ˆå»æ‰å•ä½åçš„éƒ¨åˆ†ï¼‰
            potential_numeric = value_str[:-len(unit)].strip()
            
            # éªŒè¯æ•°å€¼éƒ¨åˆ†æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ•°å€¼æ ¼å¼ï¼ˆåŒ…æ‹¬å¤åˆæ ¼å¼å¦‚ 200x160ï¼‰
            # å…è®¸ï¼šæ•°å­—ã€å°æ•°ç‚¹ã€xã€<ã€>ã€ç©ºæ ¼
            if re.match(r'^[0-9]+(?:\.[0-9]+)?(?:\s*[xÃ—]\s*[0-9]+(?:\.[0-9]+)?)*\s*[<>]?\s*$', potential_numeric, re.IGNORECASE):
                matched_unit = unit
                numeric_part = potential_numeric.strip()
                break
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†å•ä½ï¼Œä½†å­—ç¬¦ä¸²åŒ…å«æ•°å­—ï¼Œå°è¯•åˆ†ç¦»
    if not matched_unit:
        # åŒ¹é…æ¨¡å¼ï¼šæ•°å­—éƒ¨åˆ† + éæ•°å­—éƒ¨åˆ†
        match = re.match(r'^([0-9]+(?:\.[0-9]+)?(?:\s*[xÃ—]\s*[0-9]+(?:\.[0-9]+)?)*\s*[<>]?\s*)(.*?)$', value_str, re.IGNORECASE)
        if match:
            numeric_part = match.group(1).strip()
            unit_part = match.group(2).strip()
            if unit_part:  # å¦‚æœæœ‰å•ä½éƒ¨åˆ†
                matched_unit = unit_part
    
    return numeric_part, matched_unit

class AgentState(TypedDict):
    messages: list
    qwen: Any
    gpt: Any
    formatted_table: Any
    row_index: dict
    image_content: dict
    context: dict
    next: str

# Dynamically create an initial state with sensible defaults
def init_typed_dict(cls: TypedDict):
    hints = get_type_hints(cls)
    default_values = {
        list: [],
        dict: {},
        str: "",
        int: 0,
        float: 0.0,
        bool: False,
    }

    state = {}
    for key, hint in hints.items():
        # handle special case of typing.List, typing.Dict, etc.
        origin = getattr(hint, '__origin__', hint)
        state[key] = default_values.get(origin, None)
    return state


def init_llms(state: AgentState):
    """
    Initialize Qwen and OpenAI models in the state
    """
    state = init_typed_dict(AgentState)

    # Initialize Qwen model. Just use the OpenAI API for now. Because there is no guarantee langchain supports qwen well
    state["qwen"] = OpenAI(
        # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
        api_key=os.getenv('DASHSCOPE_API_KEY'),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    # Initialize GPT model
    state["gpt"] = ChatOpenAI(
        model="gpt-4o",
        max_tokens=1024,
        temperature=0.7
    )

    state['messages'].append({
        "role": "system",
        "content": SYSTEM_PROMPT
    })

    state['formatted_table'] = create_formatted_df()
    state['row_index'] = ROW_INDEX

    return state

def init_llms_for_ocr(state: AgentState):
    """
    Initialize Qwen and OpenAI models in the state for OCR only (without creating formatted_df)
    """
    state = init_typed_dict(AgentState)

    # Initialize Qwen model. Just use the OpenAI API for now. Because there is no guarantee langchain supports qwen well
    state["qwen"] = OpenAI(
        # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
        api_key=os.getenv('DASHSCOPE_API_KEY'),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    # Initialize GPT model
    state["gpt"] = ChatOpenAI(
        model="gpt-4o",
        max_tokens=1024,
        temperature=0.7
    )

    state['messages'].append({
        "role": "system",
        "content": SYSTEM_PROMPT
    })

    # æ³¨é‡Šæ‰OCRé˜¶æ®µçš„è¡¨æ ¼åˆ›å»ºï¼Œåªåœ¨æœ€ç»ˆåˆ†ææ—¶åˆ›å»º
    # state['formatted_table'] = create_formatted_df()
    # state['row_index'] = ROW_INDEX

    return state

# Define the response generation node
def create_input_node(state: AgentState):
    """Create a node for handling user input and generating responses."""
    
    # Default values
    default_image_path = os.path.join(ROOT_DIR, "../../data/input_2.jpg")
    default_question = "è¯·åˆ†æè¿™å¼ åŒ»ç–—å›¾åƒå¹¶æä¾›è¯Šæ–­å»ºè®®ã€‚"
    
    image_path = default_image_path
    question = default_question
    
    # Get user input or use defaults
    # DEBUG æ¨¡å¼ä¸‹è·³è¿‡è¾“å…¥
    if os.environ.get('DEBUG', '0') == '0':
        try:
            user_image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„): ").strip()
            user_question = input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤é—®é¢˜): ").strip()
            if user_image_path:
                image_path = user_image_path
            if user_question:
                question = user_question
        except:
            pass
    
    # Read and encode the image
    try:
        image_path = Path(image_path)
        if not image_path.exists():
            print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°å›¾ç‰‡ {image_path}ï¼Œè¯·é‡æ–°è¾“å…¥")
            raise RuntimeError(f"æ‰¾ä¸åˆ°å›¾ç‰‡ {image_path}")
            
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
        # Create image content in the format expected by the API
        image_content = {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}"
            }
        }

        state['image_content'] = image_content
        
        # Add the message to state
        state["messages"].append({
            "role": "user",
            "content": [
                image_content,
                {"type": "text", "text": question}
            ],
            "content_type": "image"
        })
        
    except Exception as e:
        print(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        # If image processing fails, fall back to text-only
        state["messages"].append({
            "role": "user",
            "content": question,
            "content_type": "text"
        })
    
    return state


def ocr_node(state: AgentState):
    """Create a node for OCR."""
    image_content = state['image_content']
    if not image_content:
        print("Warning: There is no image content to process. Skipping OCR.")
        return state

    # Call the OCR API
    messages=[
        {
            "role": "user",
            "content": [
                image_content,
                # ä¸ºä¿è¯è¯†åˆ«æ•ˆæœï¼Œå¦‚æœä½¿ç”¨qwen-vl-ocr ç³»åˆ—æ¨¡å‹ï¼Œ ç›®å‰æ¨¡å‹å†…éƒ¨ä¼šç»Ÿä¸€ä½¿ç”¨"Read all the text in the image."è¿›è¡Œè¯†åˆ«ï¼Œç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ä¸ä¼šç”Ÿæ•ˆã€‚
                {"type": "text", "text": "Read all the text in the image"},
            ],
        }
    ]

    print("æ­£åœ¨è°ƒç”¨OCRæ¨¡å‹è·å–æ–‡æœ¬æå–ç»“æœ")

    if os.environ.get('DEBUG', '0') == '1':
        text = """CTæ£€æŸ¥æŠ¥å‘Šå•
(æ‰«ç æŸ¥çœ‹å›¾åƒ
æ£€æŸ¥å·ï¼š220901
ç”³è¯·ç§‘å®¤ï¼šå†…åˆ†æ³Œç§‘â…¡ç—…åŒº
ç”³è¯·åŒ»ç”Ÿï¼šå¼ ç²
å§“åï¼š ä½é™¢å·ï¼š2022041478 å¹´é¾„ï¼š55å² æ€§åˆ«ï¼šç”· åºŠå·ï¼š5
æ£€æŸ¥é¡¹ç›®ï¼š256æ’å† çŠ¶åŠ¨è„‰CTA
æ£€æŸ¥æ‰€è§ï¼š
å† çŠ¶åŠ¨è„‰å‘ˆå³ä¼˜åŠ¿å‹ã€‚å·¦ä¸»å¹²èµ·æºäºå·¦çª¦ï¼Œå³å† çŠ¶åŠ¨è„‰èµ·æºäºå³çª¦ã€‚
å·¦ä¸»å¹²ç®¡å£å¯è§é’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»å¾®ç‹­çª„çº¦10%ã€‚å·¦å‰é™æ”¯è¿‘æ®µç®¡å£å¯è§é’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„çº¦25%ï¼›ä¸­æ®µç®¡å£å¯è§æ··åˆæ–‘å—ï¼Œç®¡è…”é‡åº¦ç‹­çª„çº¦85%ï¼›è¿œæ®µç®¡å£å¯è§é’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„çº¦25%ã€‚ç¬¬ä¸€ï¼Œç¬¬äºŒå¯¹è§’æ”¯æœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚å·¦å›æ—‹æ”¯ä¸­è¿œæ®µç®¡å£å¯è§éé’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„çº¦25%ï¼›è¿‘æ®µæœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚ç¬¬ä¸€ï¼Œç¬¬äºŒé’ç¼˜æ”¯æœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚ä¸­é—´æ”¯æœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚
å³å† çŠ¶åŠ¨è„‰è¿‘æ®µç®¡å£å¯è§é’™åŒ–ã€éé’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„çº¦25%ï¼›ä¸­æ®µã€è¿œæ®µæœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚å³åé™æ”¯æœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚å·¦å®¤åæ”¯æœªè§æ–‘å—åŠæ˜æ˜¾ç‹­çª„ã€‚
å¿ƒè„å„è…”å®¤ä¸å¤§ï¼Œå¿ƒè‚Œæœªè§å¼‚å¸¸å¯†åº¦å½±ã€‚
å°è±¡ï¼š
å† çŠ¶åŠ¨è„‰CTAï¼š1.å·¦ä¸»å¹²ç®¡å£é’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»å¾®ç‹­çª„ã€‚2.å·¦å‰é™æ”¯è¿‘æ®µç®¡å£é’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„ï¼›ä¸­æ®µç®¡å£æ··åˆæ–‘å—ï¼Œç®¡è…”é‡åº¦ç‹­çª„ï¼›è¿œæ®µç®¡å£é’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„ã€‚3.å·¦å›æ—‹æ”¯ä¸­è¿œæ®µç®¡å£éé’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„ã€‚4.å³å† çŠ¶åŠ¨è„‰è¿‘æ®µç®¡å£é’™åŒ–ã€éé’™åŒ–æ–‘å—ï¼Œç®¡è…”è½»åº¦ç‹­çª„ã€‚
æ£€æŸ¥æ—¥æœŸï¼š2022-09-08 å®¡æ ¸åŒ»å¸ˆï¼š
æŠ¥å‘ŠåŒ»å¸ˆï¼š
æ³¨ï¼š1.æœ¬æŠ¥å‘Šä»…ä¾›ä¸´åºŠç§‘å®¤ç”³è¯·åŒ»ç”Ÿè¯Šæ²»å‚è€ƒï¼
2.äºŒç»´ç é“¾æ¥å›¾åƒï¼Œè¯·å¦¥å–„ä¿å­˜æœ¬æŠ¥å‘Šï¼
æŠ¥å‘Šæ—¶é—´ï¼š2022-09-08 17:19:39
        """
    else:
        completion = state["qwen"].chat.completions.create(
            model="qwen-vl-ocr",
            messages=state['messages']
        )
        text = completion.choices[0].message.content


    state['context']['ocr'] = text
    return state


def fill_form_node(state: AgentState):
    """
    æ™ºèƒ½åˆ†æµç‰ˆæœ¬çš„è¡¨æ ¼å¡«å……èŠ‚ç‚¹
    
    å·¥ä½œæµç¨‹ï¼š
    1. å…ˆè¯†åˆ«æŠ¥å‘Šç±»å‹ï¼ˆCTA æˆ– è¶…å£°ï¼‰
    2. æ ¹æ®æŠ¥å‘Šç±»å‹é€‰æ‹©ç›¸åº”çš„å¤„ç†é€»è¾‘
    3. è¾“å‡ºç»Ÿä¸€çš„æ ¼å¼
    """
    print("ğŸš€ å¼€å§‹æ™ºèƒ½ç»“æ„åŒ–æå–...")
    
    # è·å–åŸºæœ¬æ•°æ®
    ocr = state['context']['ocr']
    formatted_table = state['formatted_table']
    row_index = state['row_index']
    qwen = state["qwen"]
    
    # ==============================================================
    # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½è¯†åˆ«æŠ¥å‘Šç±»å‹
    # ==============================================================
    print("ğŸ“‹ æ­£åœ¨è¯†åˆ«æŠ¥å‘Šç±»å‹...")
    
    classifier_prompt = REPORT_CLASSIFIER_PROMPT.format(ocr_text=ocr)
    try:
        completion = qwen.chat.completions.create(
            model="qwen-max-0125",
            messages=[
                {'role': 'system', 'content': SYSTEM_PROMPT},
                {'role': 'user', 'content': classifier_prompt}
            ]
        )
        classifier_text = completion.choices[0].message.content
        # print(f"åˆ†ç±»ç»“æœåŸæ–‡: {classifier_text}")
        
        classification_result = safe_json_load(classifier_text)
        if classification_result and 'report_type' in classification_result:
            report_type = classification_result['report_type']
            confidence = classification_result.get('confidence', 'æœªçŸ¥')
            reason = classification_result.get('reason', 'æ— ç†ç”±')
            print(f"âœ… æŠ¥å‘Šç±»å‹è¯†åˆ«å®Œæˆ: {report_type} (ç½®ä¿¡åº¦: {confidence})")
            print(f"   åˆ¤æ–­ç†ç”±: {reason}")
        else:
            print("âš ï¸ æŠ¥å‘Šç±»å‹è¯†åˆ«å¤±è´¥ï¼Œé»˜è®¤æŒ‰CTAå¤„ç†")
            report_type = "CTA"
    except Exception as e:
        print(f"âŒ æŠ¥å‘Šç±»å‹è¯†åˆ«å‡ºé”™: {e}ï¼Œé»˜è®¤æŒ‰CTAå¤„ç†")
        report_type = "CTA"
    
    # åˆå§‹åŒ–top_data
    top_data = {}
    
    # ==============================================================
    # ç¬¬äºŒæ­¥ï¼šæ ¹æ®æŠ¥å‘Šç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘
    # ==============================================================
    
    if report_type == "CTA":
        print("ğŸ” æŒ‰å† è„‰CTAæŠ¥å‘Šå¤„ç†...")
        
        # CTAæŠ¥å‘Šçš„é¡¶éƒ¨ä¿¡æ¯æå–
        header_data = [["å† çŠ¶åŠ¨è„‰é’™åŒ–æ€»ç§¯åˆ†", "LM", "LAD", "LCX", "RCA"]]
        
        # æå–é¡¶éƒ¨åŸºæœ¬ä¿¡æ¯
        for row in header_data:
            input_prompt = FILL_IN_FORM_PROMPT.format(ocr_text=ocr, key_info=row)
            try:
                completion = qwen.chat.completions.create(
                    model="qwen-max-0125",
                    messages=[
                        {'role': 'system', 'content': SYSTEM_PROMPT},
                        {'role': 'user', 'content': input_prompt}
                    ]
                )
                text = completion.choices[0].message.content
                tmp = safe_json_load(text)
                if tmp is not None:
                    for k in tmp:
                        top_data[k] = tmp[k] if tmp[k] != "NO" else ""
            except Exception as e:
                print(f"âš ï¸ CTAé¡¶éƒ¨ä¿¡æ¯æå–å¤±è´¥: {e}")
        
        # æå–CTAä¸“ç”¨çš„åˆ†ç±»ä¿¡æ¯
        cta_prompts = [
            FILLIN_PROMPT_2.format(ocr_text=ocr),  # å† çŠ¶åŠ¨è„‰èµ·æºã€èµ°å½¢åŠç»ˆæ­¢
            FILLIN_PROMPT_3.format(ocr_text=ocr),  # å† è„‰ä¼˜åŠ¿å‹
            FILLIN_PROMPT_4.format(ocr_text=ocr)   # å¼‚å¸¸æè¿°
        ]
        
        for input_prompt in cta_prompts:
            try:
                completion = qwen.chat.completions.create(
                    model="qwen-max-0125",
                    messages=[
                        {'role': 'system', 'content': SYSTEM_PROMPT},
                        {'role': 'user', 'content': input_prompt}
                    ]
                )
                text = completion.choices[0].message.content
                tmp = safe_json_load(text)
                if tmp is not None and 'key_name' in tmp and 'result' in tmp:
                    top_data[tmp['key_name']] = tmp['result']
            except Exception as e:
                print(f"âš ï¸ CTAåˆ†ç±»ä¿¡æ¯æå–å¤±è´¥: {e}")

        # å¹¶è¡Œå¤„ç†CTAçš„55ä¸ªå† è„‰èŠ‚æ®µ
        print("ğŸ”„ å¼€å§‹å¹¶è¡Œå¤„ç†å† è„‰èŠ‚æ®µ...")

        import concurrent.futures
        from functools import partial
        
        def process_location(location, ocr, qwen, row_index, system_prompt):
            """å¤„ç†å•ä¸ªå† è„‰èŠ‚æ®µçš„å‡½æ•°ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œ"""
            if location not in row_index:
                return None, None, None
            
            ridx = row_index[location]
            
            input_prompt = FILLIN_PROMPT_5.format(ocr_text=ocr, location=location)
            
            # å®ç°é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
            max_retries = 3
            attempt = 0
            
            while attempt < max_retries:
                try:
                    completion = qwen.chat.completions.create(
                        model="qwen-max-0125",
                        messages=[
                            {'role': 'system', 'content': system_prompt},
                            {'role': 'user', 'content': input_prompt}
                        ]
                    )
                    text = completion.choices[0].message.content
                    tmp = safe_json_load(text)
                    return location, ridx, tmp
                except Exception as e:
                    attempt += 1
                    if attempt < max_retries:
                        # æŒ‡æ•°é€€é¿ï¼šç­‰å¾…æ—¶é—´ä¸º 2^attempt ç§’ï¼Œæœ€å¤§ç­‰å¾…32ç§’
                        wait_time = min(2 ** attempt, 32)
                        import time
                        time.sleep(wait_time)
                    else:
                        print(f"âŒ {location} å¤„ç†å¤±è´¥: {e}")
                        return location, ridx, None
            
            return location, ridx, None
        
        # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„ä½ç½®
        locations_to_process = []
        for i in range(len(formatted_table)):
            location = formatted_table.iloc[i]["åç§°"]
            if location in row_index:
                locations_to_process.append(location)
        
        # å¹¶è¡Œå¤„ç†
        process_func = partial(process_location, ocr=ocr, qwen=qwen, row_index=row_index, system_prompt=SYSTEM_PROMPT)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            results = list(executor.map(process_func, locations_to_process))
        
        # æ›´æ–°è¡¨æ ¼ - åªæ›´æ–°CTAç›¸å…³çš„å­—æ®µ
        updatable_columns = ["æ–‘å—ç§ç±»", "ç±»å‹", "ç—‡çŠ¶", "æ•°å€¼", "ç‹­çª„ç¨‹åº¦", "é—­å¡"]
        all_extracted_data = {}  # æ”¶é›†æ‰€æœ‰æå–åˆ°çš„æ•°æ®ç”¨äºåç»­åŠ¨æ€æ·»åŠ 
        
        for location, ridx, tmp in results:
            if tmp is not None:
                # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ•°æ®ï¼ˆä¸æ˜¯é»˜è®¤çš„"-"å€¼ï¼‰
                has_real_data = False
                for col in updatable_columns:
                    value = tmp.get(col, "")
                    if value == "NO":
                        value = ""
                    if value and value != "-":
                        formatted_table.at[ridx, col] = value
                        if col == "æ•°å€¼" and value != "-":
                            has_real_data = True
                            all_extracted_data[location] = value
                
                if has_real_data:
                    print(f"âœ… CTAåŒ¹é…æˆåŠŸ: {location}")
        
        # æ”¶é›†æ‰€æœ‰å¯èƒ½è¢«é—æ¼çš„CTAæ•°æ®ï¼Œæ·»åŠ åˆ°è¡¨æ ¼åº•éƒ¨
        print("ğŸ“Š æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„CTAæ•°æ®...")
        try:
            # ä½¿ç”¨é€šç”¨æå–promptæ‰¾å‡ºå¯èƒ½é—æ¼çš„å† è„‰ç›¸å…³æ•°æ®
            cta_general_prompt = f"""
æˆ‘å°†ç»™ä½ ä¸€æ®µå† è„‰CTAè¯Šæ–­æŠ¥å‘Šç»è¿‡OCRæå–ä¹‹åçš„æ–‡æœ¬ã€‚è¯·ä»ä¸­æå–æ‰€æœ‰å…·ä½“çš„å† è„‰èŠ‚æ®µä¿¡æ¯å’Œæµ‹é‡æ•°å€¼ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å¯èƒ½æ²¡æœ‰åŒ…å«åœ¨ä»¥ä¸‹å·²çŸ¥é¡¹ç›®ä¸­çš„æ•°æ®ï¼š

**å·²çŸ¥é¡¹ç›®ï¼š**
{', '.join(all_extracted_data.keys())}

**åŒ»ç–—è¯Šæ–­æŠ¥å‘Šï¼š**
{ocr}

**æå–è§„åˆ™ï¼š**
1. é‡ç‚¹å…³æ³¨å† è„‰èŠ‚æ®µï¼ˆå¦‚"å·¦ä¸»å¹²"ã€"å‰é™æ”¯"ã€"å›æ—‹æ”¯"ã€"å³å† "çš„å„ä¸ªåˆ†æ®µï¼‰
2. æå–æ–‘å—ã€ç‹­çª„ã€é’™åŒ–ç­‰ç›¸å…³ä¿¡æ¯
3. åŒ…å«å…·ä½“çš„ç‹­çª„ç¨‹åº¦æ•°å€¼

**è¿”å›æ ¼å¼ï¼š**
è¯·ä»¥JSONæ ¼å¼è¿”å›æ‰€æœ‰å† è„‰ç›¸å…³æ•°æ®ï¼š
{{
"å† è„‰èŠ‚æ®µæˆ–æµ‹é‡é¡¹ç›®": "ç›¸å…³ä¿¡æ¯æˆ–æ•°å€¼",
"å† è„‰èŠ‚æ®µæˆ–æµ‹é‡é¡¹ç›®": "ç›¸å…³ä¿¡æ¯æˆ–æ•°å€¼",
...
}}

**åªè¿”å›JSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚**
"""
            
            completion = qwen.chat.completions.create(
                model="qwen-max-0125",
                messages=[
                    {'role': 'system', 'content': SYSTEM_PROMPT},
                    {'role': 'user', 'content': cta_general_prompt}
                ]
            )
            cta_data_text = completion.choices[0].message.content
            cta_data = safe_json_load(cta_data_text)
            
            if cta_data:
                # æ‰¾å‡ºæœªåŒ¹é…çš„æ•°æ®
                unmatched_data = []
                for key, value in cta_data.items():
                    # æ£€æŸ¥è¿™ä¸ªæ•°æ®æ˜¯å¦å·²ç»è¢«åŒ¹é…è¿‡
                    was_matched = any(str(all_extracted_data.get(existing_key, "")) == str(value) 
                                    for existing_key in all_extracted_data.keys())
                    
                    # åŒæ—¶æ£€æŸ¥keyæ˜¯å¦å·²ç»åœ¨ç°æœ‰è¡¨æ ¼çš„åç§°åˆ—ä¸­
                    key_exists = any(key in str(formatted_table.iloc[i]["åç§°"]) or 
                                   str(formatted_table.iloc[i]["åç§°"]) in key 
                                   for i in range(len(formatted_table)))
                    
                    if not was_matched and not key_exists and value and value != "-":
                        unmatched_data.append((key, value))
                
                # å°†æœªåŒ¹é…çš„æ•°æ®æ·»åŠ åˆ°è¡¨æ ¼åº•éƒ¨
                if unmatched_data:
                    print(f"ğŸ“‹ å‘ç° {len(unmatched_data)} ä¸ªæœªåŒ¹é…çš„CTAæ•°æ®ï¼Œæ·»åŠ åˆ°è¡¨æ ¼åº•éƒ¨...")
                    
                    import pandas as pd
                    for key, value in unmatched_data:
                        # åˆ†ç¦»æ•°å€¼å’Œå•ä½
                        pure_value, extracted_unit = separate_value_and_unit(str(value))
                        
                        new_row = {
                            "åç§°": key,
                            "è‹±æ–‡": "",  # ä¸æ¨æµ‹è‹±æ–‡ï¼Œä¿æŒç©ºç™½
                            "æ–‘å—ç§ç±»": "",
                            "ç±»å‹": "",
                            "ç—‡çŠ¶": "",
                            "æ•°å€¼": pure_value,
                            "å•ä½": extracted_unit,  # è‡ªåŠ¨æå–çš„å•ä½
                            "ç‹­çª„ç¨‹åº¦": "",
                            "é—­å¡": ""
                        }
                        
                        # ä½¿ç”¨pd.concatæ·»åŠ æ–°è¡Œåˆ°è¡¨æ ¼æœ€å‰é¢
                        new_row_df = pd.DataFrame([new_row])
                        formatted_table = pd.concat([new_row_df, formatted_table], ignore_index=True)
                        
                        print(f"â• æ·»åŠ æ–°è¡Œ: {key} = {value}")
                        
        except Exception as e:
            print(f"âš ï¸ CTAè¡¥å……æå–å¤±è´¥: {e}")
        
        print("âœ… CTAæŠ¥å‘Šå¤„ç†å®Œæˆ")
    
    elif report_type == "Ultrasound":
        print("ğŸ«€ æŒ‰å¿ƒè„è¶…å£°æŠ¥å‘Šå¤„ç†...")
        
        # è¶…å£°æŠ¥å‘Šçš„é€šç”¨å¼‚å¸¸æè¿°æå–
        try:
            input_4 = FILLIN_PROMPT_4.format(ocr_text=ocr)
            completion = qwen.chat.completions.create(
                model="qwen-max-0125",
                messages=[
                    {'role': 'system', 'content': SYSTEM_PROMPT},
                    {'role': 'user', 'content': input_4}
                ]
            )
            text = completion.choices[0].message.content
            tmp = safe_json_load(text)
            if tmp is not None and 'key_name' in tmp and 'result' in tmp:
                top_data[tmp['key_name']] = tmp['result']
        except Exception as e:
            print(f"âš ï¸ è¶…å£°å¼‚å¸¸æè¿°æå–å¤±è´¥: {e}")
        
        # å¹¶è¡Œå¤„ç†è¶…å£°çš„55ä¸ªæµ‹é‡é¡¹ç›®
        print("ğŸ”„ å¼€å§‹å¹¶è¡Œå¤„ç†è¶…å£°æµ‹é‡é¡¹ç›®...")
        
        import concurrent.futures
        from functools import partial
        
        # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„ä½ç½®
        locations_to_process = []
        for i in range(len(formatted_table)):
            location = formatted_table.iloc[i]["åç§°"]
            if location in row_index:
                locations_to_process.append(location)
        
        # å¹¶è¡Œå¤„ç†
        process_func = partial(process_ultrasound_location, ocr=ocr, qwen=qwen, row_index=row_index, system_prompt=SYSTEM_PROMPT)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            results = list(executor.map(process_func, locations_to_process))
        
        # æ›´æ–°è¡¨æ ¼ - åªæ›´æ–°è¶…å£°ç›¸å…³çš„å­—æ®µ
        updatable_columns = ["æ–‘å—ç§ç±»", "ç±»å‹", "ç—‡çŠ¶", "æ•°å€¼", "ç‹­çª„ç¨‹åº¦", "é—­å¡"]
        all_extracted_data = {}  # æ”¶é›†æ‰€æœ‰æå–åˆ°çš„æ•°æ®ç”¨äºåç»­åŠ¨æ€æ·»åŠ 
        
        for location, ridx, tmp in results:
            if tmp is not None:
                # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ•°æ®ï¼ˆä¸æ˜¯é»˜è®¤çš„"-"å€¼ï¼‰
                has_real_data = False
                for col in updatable_columns:
                    value = tmp.get(col, "")
                    if value and value != "NO" and value != "-":
                        # ç‰¹æ®Šå¤„ç†"æ•°å€¼"å­—æ®µï¼šè‡ªåŠ¨åˆ†ç¦»æ•°å€¼å’Œå•ä½
                        if col == "æ•°å€¼":
                            pure_value, extracted_unit = separate_value_and_unit(value)
                            formatted_table.at[ridx, col] = pure_value
                            
                            # å¦‚æœæå–åˆ°äº†å•ä½ï¼Œå¹¶ä¸”å½“å‰è¡Œçš„å•ä½åˆ—ä¸ºç©ºï¼Œåˆ™å¡«å…¥å•ä½
                            if extracted_unit and (pd.isna(formatted_table.at[ridx, "å•ä½"]) or formatted_table.at[ridx, "å•ä½"] == ""):
                                formatted_table.at[ridx, "å•ä½"] = extracted_unit
                                
                            if pure_value != "-":
                                has_real_data = True
                                all_extracted_data[location] = pure_value
                        else:
                            formatted_table.at[ridx, col] = value
                            if col == "æ•°å€¼" and value != "-":
                                has_real_data = True
                                all_extracted_data[location] = value
                
                if has_real_data:
                    print(f"âœ… è¶…å£°åŒ¹é…æˆåŠŸ: {location}")
        
        # æ”¶é›†æ‰€æœ‰å¯èƒ½è¢«é—æ¼çš„æµ‹é‡å€¼ï¼Œæ·»åŠ åˆ°è¡¨æ ¼åº•éƒ¨
        # è¿™é‡Œå¯ä»¥å®ç°ä¸€ä¸ªé€šç”¨çš„è¡¥å……æå–é€»è¾‘
        print("ğŸ“Š æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„æµ‹é‡å€¼...")
        try:
            # ä½¿ç”¨é€šç”¨æå–promptæ‰¾å‡ºå¯èƒ½é—æ¼çš„æµ‹é‡å€¼
            general_extract_prompt = f"""
æˆ‘å°†ç»™ä½ ä¸€æ®µå¿ƒè„è¶…å£°è¯Šæ–­æŠ¥å‘Šç»è¿‡OCRæå–ä¹‹åçš„æ–‡æœ¬ã€‚è¯·ä»ä¸­æå–æ‰€æœ‰å…·ä½“çš„æµ‹é‡æ•°å€¼å’Œå‚æ•°ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å¯èƒ½æ²¡æœ‰åŒ…å«åœ¨ä»¥ä¸‹å·²çŸ¥é¡¹ç›®ä¸­çš„æµ‹é‡å€¼ï¼š

**å·²çŸ¥é¡¹ç›®ï¼š**
{', '.join(all_extracted_data.keys())}

**ä¸Šä¸‹æ–‡è¯­ä¹‰å…³è”è§„åˆ™ï¼š**
åœ¨åˆ†ææŠ¥å‘Šæ—¶ï¼Œè¯·ç‰¹åˆ«æ³¨æ„ä¸Šä¸‹å¥ä¹‹é—´çš„è¯­ä¹‰å…³è”ï¼š
- å¦‚æœå‰ä¸€å¥æåˆ°äº†ç‰¹å®šéƒ¨ä½çš„å¤šä¸ªå‚æ•°ï¼ˆå¦‚Aã€Bå‚æ•°ï¼‰
- è€Œç´§æ¥ç€çš„ä¸‹ä¸€å¥åªæåˆ°äº†è¿™äº›å‚æ•°çš„è®¡ç®—ç»“æœï¼ˆå¦‚A/Bæ¯”å€¼ã€å˜åŒ–ç‡ã€æŒ‡æ•°ç­‰ï¼‰
- è¯·å°†è¯¥è®¡ç®—ç»“æœå½’å±äºå‰ä¸€å¥æåˆ°çš„éƒ¨ä½ï¼Œå½¢æˆå®Œæ•´çš„æµ‹é‡é¡¹ç›®åç§°

**ç¤ºä¾‹ï¼š**
- "å·¦å¿ƒæˆ¿æ”¶ç¼©åŠŸèƒ½ï¼šæ”¶ç¼©æœŸé¢ç§¯15cmÂ²ï¼Œèˆ’å¼ æœŸé¢ç§¯20cmÂ²ã€‚é¢ç§¯å˜åŒ–åˆ†æ•°ä¸º25%ã€‚" 
  â†’ åº”è¯†åˆ«å‡º"å·¦å¿ƒæˆ¿é¢ç§¯å˜åŒ–åˆ†æ•°"
- "è‚¾è„è¡€æµè¯„ä¼°ï¼šæ”¶ç¼©æœŸæµé€Ÿ1.2m/sï¼Œèˆ’å¼ æœŸæµé€Ÿ0.8m/sã€‚é˜»åŠ›æŒ‡æ•°0.65ã€‚"
  â†’ åº”è¯†åˆ«å‡º"è‚¾è„é˜»åŠ›æŒ‡æ•°"
- "èƒ¸ä¸»åŠ¨è„‰å¼¹æ€§ï¼šæ”¶ç¼©æœŸå†…å¾„28mmï¼Œèˆ’å¼ æœŸå†…å¾„26mmã€‚æ‰©å¼ æ€§7.7%ã€‚"
  â†’ åº”è¯†åˆ«å‡º"èƒ¸ä¸»åŠ¨è„‰æ‰©å¼ æ€§"

**æå–è¦æ±‚ï¼š**
1. æå–å®Œæ•´çš„è§£å‰–éƒ¨ä½+æµ‹é‡å‚æ•°ç»„åˆ
2. ä¸è¦é—æ¼ç”±å¤šä¸ªå¥å­å…±åŒæè¿°çš„å¤åˆæµ‹é‡é¡¹ç›®
3. æ³¨æ„æ¯”å€¼ã€åˆ†æ•°ã€æŒ‡æ•°ã€ç™¾åˆ†æ¯”ç­‰è®¡ç®—ç»“æœä¸å…¶å¯¹åº”éƒ¨ä½çš„å…³è”

**åŒ»ç–—è¯Šæ–­æŠ¥å‘Šï¼š**
{ocr}

**è¿”å›æ ¼å¼ï¼š**
è¯·ä»¥JSONæ ¼å¼è¿”å›æ‰€æœ‰æµ‹é‡å€¼ï¼ˆåŒ…æ‹¬å·²çŸ¥çš„å’Œæ–°å‘ç°çš„ï¼‰ï¼š
{{
"æµ‹é‡é¡¹ç›®åç§°": "æ•°å€¼",
"æµ‹é‡é¡¹ç›®åç§°": "æ•°å€¼",
...
}}

**åªè¿”å›JSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚**
"""
            
            completion = qwen.chat.completions.create(
                model="qwen-max-0125",
                messages=[
                    {'role': 'system', 'content': SYSTEM_PROMPT},
                    {'role': 'user', 'content': general_extract_prompt}
                ]
            )
            general_data_text = completion.choices[0].message.content
            general_data = safe_json_load(general_data_text)
            
            if general_data:
                # æ‰¾å‡ºæœªåŒ¹é…çš„æ•°æ®
                unmatched_data = []
                for key, value in general_data.items():
                    # æ£€æŸ¥è¿™ä¸ªæ•°æ®æ˜¯å¦å·²ç»è¢«åŒ¹é…è¿‡
                    was_matched = any(str(all_extracted_data.get(existing_key, "")) == str(value) 
                                    for existing_key in all_extracted_data.keys())
                    
                    if not was_matched and value and value != "-":
                        unmatched_data.append((key, value))
                
                # å°†æœªåŒ¹é…çš„æ•°æ®æ·»åŠ åˆ°è¡¨æ ¼åº•éƒ¨
                if unmatched_data:
                    print(f"ğŸ“‹ å‘ç° {len(unmatched_data)} ä¸ªæœªåŒ¹é…çš„æµ‹é‡å€¼ï¼Œæ·»åŠ åˆ°è¡¨æ ¼åº•éƒ¨...")
                    
                    import pandas as pd
                    for key, value in unmatched_data:
                        # åˆ†ç¦»æ•°å€¼å’Œå•ä½
                        pure_value, extracted_unit = separate_value_and_unit(str(value))
                        
                        new_row = {
                            "åç§°": key,
                            "è‹±æ–‡": "",  # ä¸æ¨æµ‹è‹±æ–‡ï¼Œä¿æŒç©ºç™½
                            "æ–‘å—ç§ç±»": "",
                            "ç±»å‹": "",
                            "ç—‡çŠ¶": "",
                            "æ•°å€¼": pure_value,
                            "å•ä½": extracted_unit,  # è‡ªåŠ¨æå–çš„å•ä½
                            "ç‹­çª„ç¨‹åº¦": "",
                            "é—­å¡": ""
                        }
                        
                        # ä½¿ç”¨pd.concatæ·»åŠ æ–°è¡Œåˆ°è¡¨æ ¼æœ€å‰é¢
                        new_row_df = pd.DataFrame([new_row])
                        formatted_table = pd.concat([new_row_df, formatted_table], ignore_index=True)
                        
                        print(f"â• æ·»åŠ æ–°è¡Œ: {key} = {value}")
                        
        except Exception as e:
            print(f"âš ï¸ è¡¥å……æå–å¤±è´¥: {e}")
        
        # åœ¨è¶…å£°æŠ¥å‘Šå¤„ç†å®Œæˆåï¼Œæ·»åŠ E/Aæ¯”å€¼è‡ªåŠ¨è®¡ç®—
        if report_type == "Ultrasound":
            formatted_table = calculate_ea_ratios(formatted_table)
        
        print("âœ… è¶…å£°æŠ¥å‘Šå¤„ç†å®Œæˆ")
    
    else:
        print(f"âš ï¸ æœªçŸ¥æŠ¥å‘Šç±»å‹: {report_type}ï¼Œè·³è¿‡å¤„ç†")
    
    # ==============================================================
    # ç¬¬ä¸‰æ­¥ï¼šæ›´æ–°çŠ¶æ€ä¸­çš„è¡¨æ ¼å¹¶ä¿å­˜ç»“æœ
    # ==============================================================
    
    # å¦‚æœçŠ¶æ€ä¸­æœ‰å¤„ç†æ—¶é—´çš„èµ·ç‚¹ï¼Œæ‰“å°å¤„ç†æ—¶é—´
    if 'process_start_time' in state['context']:
        end_timer_and_print(state['context']['process_start_time'], 
                          state['context'].get('current_file_name', 'unknown'), 
                          state['context'].get('file_type', 'file'))
    
    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    
    # æ›´æ–°çŠ¶æ€ä¸­çš„è¡¨æ ¼ï¼ˆå¯èƒ½å·²ç»è¢«åŠ¨æ€æ‰©å±•ï¼‰
    state['formatted_table'] = formatted_table
    
    save_df_to_cache(formatted_table, "qwen_cache")

    # åŠ è½½å¹¶æ˜¾ç¤ºç»“æœ
    df = load_df_from_cache("qwen_cache")
    state['context']['df'] = df
    
    print("ğŸ¯ æ˜¾ç¤ºç»“æœ...")
    show_popup_with_df(df, top_data)

    print("âœ¨ æ™ºèƒ½ç»“æ„åŒ–æå–å®Œæˆï¼")
    return state


            

# Define the response generation node
def create_response_node(state: AgentState):
    """Create a node for handling user input and generating responses."""
    # Get the last user message
    last_message = next((m for m in reversed(state["messages"]) if m["role"] == "user"), None)
    
    if not last_message:
        return state
        
    # Get content and content type
    content = last_message["content"]
    content_type = last_message.get("content_type", "text")
    
    # Get response from LLM using state's llm
    # result = state["gpt"].invoke([system_message, user_message])
    completion = call_qwen_vl_api(state)
    
    # Add the response to messages
    state["messages"].append({
        "role": "assistant",
        "content": completion,
        "content_type": "text"
    })
    
    return state
    
def show_results(state: AgentState):
    """Show the results of the agent's response."""
    # Get the last assistant message
    last_assistant_message = next((m for m in reversed(state["messages"]) if m["role"] == "assistant"), None)

    if last_assistant_message:
        print("Agent Response:")
        print(last_assistant_message["content"])
    else:
        print("No response from the agent.")
    return state

# Build the complete agent
def build_medical_agent():
    """Build a simplified medical agent with a single node."""
    
    graph = StateGraph(AgentState)
    
    graph.add_node("init_llms", init_llms)
    graph.add_node("input_node", create_input_node)
    graph.add_node("ocr_node", ocr_node)
    graph.add_node("response_node", create_response_node)
    graph.add_node("show_results", show_results)
    graph.add_node("fill_form_node", fill_form_node)
    # Set the entry point and edge
    graph.set_entry_point("init_llms")
    graph.add_edge("init_llms", "input_node")
    graph.add_edge("input_node", "ocr_node")
    graph.add_edge("ocr_node", "fill_form_node")
    # graph.add_edge("ocr_node", "response_node")
    # graph.add_edge("response_node", "show_results")
    # Compile the graph
    return graph.compile()